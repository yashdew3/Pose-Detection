{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe opencv-python numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2343859",
   "metadata": {},
   "source": [
    "# Save the pose-overlaid images from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd5d6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 945/948 [00:42<00:00, 22.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#Save the pose-overlaid images from videos\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "input_videos_dir = 'F:/Task/Tiger Woods Slow Mo Driver Swing  TaylorMade Golf - TaylorMade Golf (720p, h264).mp4'\n",
    "output_images_dir = 'F:/Task/output'\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cap = cv2.VideoCapture(input_videos_dir)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for frame_idx in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        output_path = os.path.join(output_images_dir, f'frame_{frame_idx:05d}.png')\n",
    "        cv2.imwrite(output_path, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d403209",
   "metadata": {},
   "source": [
    "# Write one sentence for each frame describing what visually changes\n",
    "In each frame, the pose landmarks are detected and overlaid on the image, \n",
    "showing the position and orientation of the person's body parts as they move through the golf swing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b99048",
   "metadata": {},
   "source": [
    "# Run any pose-estimation model on those frames using mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ae194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [01:16<00:00, 12.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#Run any pose-estimation model on those frames using mediapipe\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "input_images_dir = 'F:/Task/output'\n",
    "output_images_dir = 'F:/Task/pose_output'\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
    "    image_files = sorted([f for f in os.listdir(input_images_dir) if f.endswith('.png')])\n",
    "    for image_file in tqdm(image_files):\n",
    "        image_path = os.path.join(input_images_dir, image_file)\n",
    "        frame = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        output_path = os.path.join(output_images_dir, image_file)\n",
    "        cv2.imwrite(output_path, frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529f1ef",
   "metadata": {},
   "source": [
    "# Write 1–2 sentences explaining why you chose that specific model\n",
    "I chose MediaPipe's Pose model because it provides real-time, accurate 2D pose estimation with a lightweight architecture, \n",
    "making it suitable for processing video frames efficiently. Additionally, it offers easy integration and robust performance across various human poses, which is ideal for analyzing motion in sports activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d9e32",
   "metadata": {},
   "source": [
    "# Arm angle: compute the angle formed by shoulder–elbow–wrist on either arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6af9624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [01:11<00:00, 13.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#Arm angle: compute the angle formed by shoulder–elbow–wrist on either arm\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "input_images_dir = 'F:/Task/output'\n",
    "output_images_dir = 'F:/Task/angle_output'\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
    "    image_files = sorted([f for f in os.listdir(input_images_dir) if f.endswith('.png')])\n",
    "    for image_file in tqdm(image_files):\n",
    "        image_path = os.path.join(input_images_dir, image_file)\n",
    "        frame = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x * frame.shape[1],\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y * frame.shape[0]]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x * frame.shape[1],\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y * frame.shape[0]]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x * frame.shape[1],\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y * frame.shape[0]]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * frame.shape[1],\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * frame.shape[0]]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x * frame.shape[1],\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y * frame.shape[0]]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x * frame.shape[1],\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y * frame.shape[0]]\n",
    "            left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            cv2.putText(frame, f'Left Arm Angle: {left_arm_angle:.2f}', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Right Arm Angle: {right_arm_angle:.2f}', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        output_path = os.path.join(output_images_dir, image_file)\n",
    "        cv2.imwrite(output_path, frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35c447",
   "metadata": {},
   "source": [
    "# Write 2–3 sentences explaining how you calculated it.\n",
    "To calculate the arm angles, I first extracted the 2D coordinates of the shoulder, elbow, and wrist landmarks for \n",
    "both arms using MediaPipe's pose estimation. I then used the cosine rule to compute the angle formed at the elbow by treating the shoulder-elbow and elbow-wrist segments as vectors. The resulting angles were then overlaid on the images for visualization.\n",
    "# Arm angle increased from 170 to 105 degrees during the swing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090b716",
   "metadata": {},
   "source": [
    "# Extract 5–10 representative frames and save the pose-overlaid images with arm angles displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "644e0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's Extract 5–10 representative frames and save the pose-overlaid images with arm angles displayed\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "input_images_dir = 'F:/Task/output'\n",
    "output_images_dir = 'F:/Task/representative_frames'\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
    "    image_files = sorted([f for f in os.listdir(input_images_dir) if f.endswith('.png')])\n",
    "    representative_indices = np.linspace(0, len(image_files) - 1, num=10, dtype=int)\n",
    "    for idx in representative_indices:\n",
    "        image_file = image_files[idx]\n",
    "        image_path = os.path.join(input_images_dir, image_file)\n",
    "        frame = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x * frame.shape[1],\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y * frame.shape[0]]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x * frame.shape[1],\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y * frame.shape[0]]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x * frame.shape[1],\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y * frame.shape[0]]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * frame.shape[1],\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * frame.shape[0]]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x * frame.shape[1],\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y * frame.shape[0]]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x * frame.shape[1],\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y * frame.shape[0]]\n",
    "            left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            cv2.putText(frame, f'Left Arm Angle: {left_arm_angle:.2f}', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Right Arm Angle: {right_arm_angle:.2f}', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        output_path = os.path.join(output_images_dir, image_file)\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        cv2.putText(frame, f'Right Arm Angle: {right_arm_angle:.2f}', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        output_path = os.path.join(output_images_dir, image_file)\n",
    "        cv2.imwrite(output_path, frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
